## Results
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 100)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               51712     
_________________________________________________________________
dense_2 (Dense)              (None, 784)               402192    
=================================================================
Total params: 453,904
Trainable params: 453,904
Non-trainable params: 0
_________________________________________________________________
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_2 (InputLayer)         (None, 784)               0         
_________________________________________________________________
dense_3 (Dense)              (None, 512)               401920    
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 513       
=================================================================
Total params: 402,433
Trainable params: 402,433
Non-trainable params: 0
_________________________________________________________________
1 D_fake: [0.6868801, 1.0] 	D_real: [0.69402635, 0.3046875] 	G: [0.7174978, 0.0]
2 D_fake: [0.67002225, 1.0] 	D_real: [0.6949189, 0.1328125] 	G: [0.7362025, 0.0]
3 D_fake: [0.6522361, 1.0] 	D_real: [0.69609195, 0.15625] 	G: [0.7540097, 0.0]
4 D_fake: [0.6363195, 1.0] 	D_real: [0.6958892, 0.171875] 	G: [0.77139723, 0.0]
5 D_fake: [0.6211947, 1.0] 	D_real: [0.69732565, 0.1328125] 	G: [0.78922254, 0.0]
6 D_fake: [0.6059468, 1.0] 	D_real: [0.6972804, 0.1953125] 	G: [0.80816305, 0.0]
7 D_fake: [0.59082305, 1.0] 	D_real: [0.69750834, 0.234375] 	G: [0.8275554, 0.0]
8 D_fake: [0.5754938, 1.0] 	D_real: [0.69847155, 0.2421875] 	G: [0.8477715, 0.0]
9 D_fake: [0.5602491, 1.0] 	D_real: [0.6981077, 0.2890625] 	G: [0.868235, 0.0]
10 D_fake: [0.5454177, 1.0] 	D_real: [0.6950444, 0.515625] 	G: [0.8892654, 0.0]
11 D_fake: [0.53039443, 1.0] 	D_real: [0.6951049, 0.4921875] 	G: [0.9109489, 0.0]
12 D_fake: [0.5157833, 1.0] 	D_real: [0.6896796, 0.78125] 	G: [0.93290687, 0.0]
13 D_fake: [0.5011874, 1.0] 	D_real: [0.6873614, 0.8203125] 	G: [0.95540845, 0.0]
14 D_fake: [0.4874385, 1.0] 	D_real: [0.68536496, 0.8203125] 	G: [0.9774938, 0.0]
15 D_fake: [0.4732943, 1.0] 	D_real: [0.6826893, 0.8203125] 	G: [1.0013039, 0.0]
16 D_fake: [0.45978057, 1.0] 	D_real: [0.67920685, 0.9140625] 	G: [1.0247073, 0.0]
17 D_fake: [0.44643417, 1.0] 	D_real: [0.67589885, 0.921875] 	G: [1.0485966, 0.0]
18 D_fake: [0.43367016, 1.0] 	D_real: [0.66454184, 0.9609375] 	G: [1.0718102, 0.0]
19 D_fake: [0.42144066, 1.0] 	D_real: [0.6613857, 0.9609375] 	G: [1.094831, 0.0]
20 D_fake: [0.40944844, 1.0] 	D_real: [0.6554577, 0.9765625] 	G: [1.1184262, 0.0]
21 D_fake: [0.39859763, 1.0] 	D_real: [0.6391022, 1.0] 	G: [1.1401997, 0.0]
22 D_fake: [0.3869207, 1.0] 	D_real: [0.63866055, 0.984375] 	G: [1.1648242, 0.0]
23 D_fake: [0.376948, 1.0] 	D_real: [0.6361948, 1.0] 	G: [1.1866152, 0.0]
24 D_fake: [0.36743602, 1.0] 	D_real: [0.62242633, 1.0] 	G: [1.2076099, 0.0]
25 D_fake: [0.35831946, 1.0] 	D_real: [0.62225735, 1.0] 	G: [1.2283473, 0.0]
26 D_fake: [0.34861526, 1.0] 	D_real: [0.6015105, 0.9921875] 	G: [1.2515568, 0.0]
27 D_fake: [0.34075302, 1.0] 	D_real: [0.5902094, 0.9921875] 	G: [1.2702268, 0.0]
28 D_fake: [0.3327823, 1.0] 	D_real: [0.58567154, 1.0] 	G: [1.2903637, 0.0]
29 D_fake: [0.32649598, 1.0] 	D_real: [0.58217454, 1.0] 	G: [1.3067298, 0.0]
30 D_fake: [0.31829625, 1.0] 	D_real: [0.55864227, 1.0] 	G: [1.3277076, 0.0]
31 D_fake: [0.31194025, 1.0] 	D_real: [0.5590924, 1.0] 	G: [1.3450191, 0.0]
32 D_fake: [0.30639017, 1.0] 	D_real: [0.52268535, 0.9921875] 	G: [1.3596795, 0.0]
33 D_fake: [0.2999164, 1.0] 	D_real: [0.5224305, 1.0] 	G: [1.377897, 0.0]
34 D_fake: [0.29617816, 1.0] 	D_real: [0.53256595, 0.984375] 	G: [1.388501, 0.0]
35 D_fake: [0.29076868, 1.0] 	D_real: [0.48523188, 1.0] 	G: [1.404696, 0.0]
36 D_fake: [0.28732264, 1.0] 	D_real: [0.49894595, 1.0] 	G: [1.4162283, 0.0]
37 D_fake: [0.28349006, 1.0] 	D_real: [0.4933167, 1.0] 	G: [1.4289808, 0.0]
38 D_fake: [0.27719998, 1.0] 	D_real: [0.47802356, 1.0] 	G: [1.4491769, 0.0]
39 D_fake: [0.27539587, 1.0] 	D_real: [0.47955889, 1.0] 	G: [1.4556814, 0.0]
40 D_fake: [0.27080524, 1.0] 	D_real: [0.4584193, 1.0] 	G: [1.4710015, 0.0]
41 D_fake: [0.2695699, 1.0] 	D_real: [0.40501857, 1.0] 	G: [1.475608, 0.0]
42 D_fake: [0.2646591, 1.0] 	D_real: [0.40047514, 1.0] 	G: [1.491988, 0.0]
43 D_fake: [0.26143938, 1.0] 	D_real: [0.42690712, 1.0] 	G: [1.5039732, 0.0]
44 D_fake: [0.25780952, 1.0] 	D_real: [0.37721187, 1.0] 	G: [1.5174243, 0.0]
45 D_fake: [0.25604486, 1.0] 	D_real: [0.41122007, 1.0] 	G: [1.5252383, 0.0]
46 D_fake: [0.2526651, 1.0] 	D_real: [0.39938527, 1.0] 	G: [1.5383613, 0.0]
47 D_fake: [0.2533079, 1.0] 	D_real: [0.3811125, 1.0] 	G: [1.538941, 0.0]
48 D_fake: [0.25324655, 1.0] 	D_real: [0.36883086, 1.0] 	G: [1.5413703, 0.0]
49 D_fake: [0.24645014, 1.0] 	D_real: [0.34727865, 1.0] 	G: [1.5667088, 0.0]
50 D_fake: [0.2467596, 1.0] 	D_real: [0.3510716, 1.0] 	G: [1.5682454, 0.0]
51 D_fake: [0.24499089, 1.0] 	D_real: [0.36372155, 1.0] 	G: [1.5769632, 0.0]
52 D_fake: [0.24213344, 1.0] 	D_real: [0.3673613, 1.0] 	G: [1.5895605, 0.0]
53 D_fake: [0.24249583, 1.0] 	D_real: [0.3672609, 1.0] 	G: [1.5925049, 0.0]
54 D_fake: [0.23776744, 1.0] 	D_real: [0.34468204, 1.0] 	G: [1.6108311, 0.0]
55 D_fake: [0.23790184, 1.0] 	D_real: [0.32844657, 1.0] 	G: [1.6121019, 0.0]
56 D_fake: [0.23228753, 1.0] 	D_real: [0.31060636, 1.0] 	G: [1.6348488, 0.0]
57 D_fake: [0.23071495, 1.0] 	D_real: [0.37109837, 1.0] 	G: [1.64424, 0.0]
58 D_fake: [0.23685727, 1.0] 	D_real: [0.34096617, 1.0] 	G: [1.6241438, 0.0]
59 D_fake: [0.23466375, 1.0] 	D_real: [0.29006624, 1.0] 	G: [1.6358992, 0.0]
60 D_fake: [0.23434347, 1.0] 	D_real: [0.32300085, 1.0] 	G: [1.6401156, 0.0]
61 D_fake: [0.23431401, 1.0] 	D_real: [0.30827373, 0.9921875] 	G: [1.6414313, 0.0]
62 D_fake: [0.24090287, 1.0] 	D_real: [0.307271, 1.0] 	G: [1.6185715, 0.0]
63 D_fake: [0.23977105, 1.0] 	D_real: [0.28065318, 1.0] 	G: [1.6288038, 0.0]
64 D_fake: [0.23344684, 1.0] 	D_real: [0.32890922, 0.9921875] 	G: [1.6532344, 0.0]
65 D_fake: [0.23359615, 1.0] 	D_real: [0.3072734, 1.0] 	G: [1.6569073, 0.0]
66 D_fake: [0.23536646, 1.0] 	D_real: [0.31507567, 1.0] 	G: [1.6540321, 0.0]
67 D_fake: [0.23315313, 1.0] 	D_real: [0.32255632, 1.0] 	G: [1.6606592, 0.0]
68 D_fake: [0.23490137, 1.0] 	D_real: [0.35522732, 0.9921875] 	G: [1.6551208, 0.0]
69 D_fake: [0.23872499, 1.0] 	D_real: [0.31019142, 1.0] 	G: [1.6464729, 0.0]
70 D_fake: [0.23971021, 1.0] 	D_real: [0.34115463, 1.0] 	G: [1.6516333, 0.0]
71 D_fake: [0.24667338, 1.0] 	D_real: [0.36449403, 0.9765625] 	G: [1.6213591, 0.0]
72 D_fake: [0.23842467, 1.0] 	D_real: [0.29775804, 0.9921875] 	G: [1.6526017, 0.0]
73 D_fake: [0.24526703, 1.0] 	D_real: [0.33938617, 0.9921875] 	G: [1.631294, 0.0]
74 D_fake: [0.24425372, 1.0] 	D_real: [0.27754673, 0.9921875] 	G: [1.6417141, 0.0]
75 D_fake: [0.24891579, 1.0] 	D_real: [0.35530296, 0.984375] 	G: [1.6330884, 0.0]
76 D_fake: [0.2463531, 1.0] 	D_real: [0.29406464, 0.984375] 	G: [1.648217, 0.0]
77 D_fake: [0.23844317, 1.0] 	D_real: [0.35344627, 0.984375] 	G: [1.6639277, 0.0]
78 D_fake: [0.23369071, 1.0] 	D_real: [0.35175216, 0.9765625] 	G: [1.6937927, 0.0]
79 D_fake: [0.23573664, 1.0] 	D_real: [0.33364877, 0.9765625] 	G: [1.6803588, 0.0]
80 D_fake: [0.22826941, 1.0] 	D_real: [0.36541417, 0.984375] 	G: [1.7042887, 0.0]
81 D_fake: [0.23282352, 1.0] 	D_real: [0.38288644, 0.9921875] 	G: [1.6889255, 0.0]
82 D_fake: [0.24670163, 1.0] 	D_real: [0.40828958, 0.9765625] 	G: [1.6474881, 0.0]
83 D_fake: [0.23997355, 1.0] 	D_real: [0.38319772, 0.9609375] 	G: [1.6658242, 0.0]
84 D_fake: [0.2403818, 1.0] 	D_real: [0.39823702, 0.984375] 	G: [1.6569504, 0.0]
85 D_fake: [0.2341922, 1.0] 	D_real: [0.40917593, 0.96875] 	G: [1.6856639, 0.0]
86 D_fake: [0.23942068, 1.0] 	D_real: [0.33723032, 0.984375] 	G: [1.6736634, 0.0]
87 D_fake: [0.2291579, 1.0] 	D_real: [0.4132511, 0.9453125] 	G: [1.70448, 0.0]
88 D_fake: [0.22894147, 1.0] 	D_real: [0.44696587, 0.9375] 	G: [1.7078437, 0.0]
89 D_fake: [0.23973264, 1.0] 	D_real: [0.3925056, 0.9609375] 	G: [1.6719601, 0.0]
90 D_fake: [0.22956681, 1.0] 	D_real: [0.4755404, 0.8984375] 	G: [1.7049862, 0.0]
91 D_fake: [0.24174899, 1.0] 	D_real: [0.4240475, 0.953125] 	G: [1.6623363, 0.0]
92 D_fake: [0.23316066, 1.0] 	D_real: [0.3907649, 0.96875] 	G: [1.705, 0.0]
93 D_fake: [0.23966616, 1.0] 	D_real: [0.44417438, 0.921875] 	G: [1.6560823, 0.0]
94 D_fake: [0.24454212, 1.0] 	D_real: [0.47538465, 0.9375] 	G: [1.656264, 0.0]
95 D_fake: [0.24432757, 1.0] 	D_real: [0.52710795, 0.8515625] 	G: [1.6542442, 0.0]
96 D_fake: [0.23665904, 1.0] 	D_real: [0.4486831, 0.953125] 	G: [1.6886855, 0.0]
97 D_fake: [0.23872483, 1.0] 	D_real: [0.466893, 0.9609375] 	G: [1.6686711, 0.0]
98 D_fake: [0.25397813, 1.0] 	D_real: [0.45314068, 0.953125] 	G: [1.6173989, 0.0]
99 D_fake: [0.25135088, 1.0] 	D_real: [0.44902015, 0.9609375] 	G: [1.6253483, 0.0]
...
